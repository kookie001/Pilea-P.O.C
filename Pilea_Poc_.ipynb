{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMyack3FLCi+se0+uShbvdY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kookie001/Pilea-P.O.C/blob/main/Pilea_Poc_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRglw88jC9DT",
        "outputId": "17b2020d-f04b-4e24-cba6-3ee60235325a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g lighthouse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buqe-wpcJQVp",
        "outputId": "2f74da52-467a-4359-d812-bf5e37a03dfe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "changed 164 packages in 17s\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K11 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y chromium-browser\n",
        "!pip install pyppeteer\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import asyncio\n",
        "from pyppeteer import launch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Function to capture a screenshot of the website\n",
        "async def capture_screenshot(url, output_file):\n",
        "    browser = await launch(args=['--no-sandbox', '--disable-setuid-sandbox']) # Added arguments to disable sandbox\n",
        "    page = await browser.newPage()\n",
        "    await page.goto(url)\n",
        "    await page.screenshot({'path': output_file, 'fullPage': True})\n",
        "    await browser.close()\n",
        "\n",
        "# ... (rest of your code remains the same) ...\n",
        "\n",
        "# Function to annotate the screenshot using OpenCV\n",
        "def annotate_screenshot(input_file, output_file):\n",
        "    image = cv2.imread(input_file)\n",
        "    height, width, _ = image.shape\n",
        "    cv2.rectangle(image, (10, 10), (width - 10, height - 10), (0, 255, 0), 5)\n",
        "    cv2.putText(image, 'Annotated Screenshot', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "    cv2.imwrite(output_file, image)\n",
        "\n",
        "# Function to generate a heatmap using Matplotlib\n",
        "def generate_heatmap(data, output_file):\n",
        "    plt.imshow(data, cmap='hot', interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.title(\"Heatmap\")\n",
        "    plt.savefig(output_file)\n",
        "    plt.close()\n",
        "\n",
        "# Function to extract text and HTML content from a website\n",
        "def extract_content(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    text = soup.get_text(strip=True)\n",
        "    html = soup.prettify()\n",
        "    return text, html\n",
        "\n",
        "# Function to run Lighthouse audit and parse the results\n",
        "def run_lighthouse(url, output_file):\n",
        "    command = [\"lighthouse\", url, \"--output=json\", f\"--output-path={output_file}\"]\n",
        "    # Capture the result of the subprocess call\n",
        "    result = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "    # Check if the command was successful\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Lighthouse command failed with error: {result.stderr}\")\n",
        "        return None  # Or handle the error appropriately\n",
        "\n",
        "    with open(output_file, 'r') as f:\n",
        "        data = f.read()\n",
        "    return data\n",
        "\n",
        "# Function to visualize Lighthouse metrics using Matplotlib\n",
        "def visualize_lighthouse_metrics(metrics, output_file):\n",
        "    labels = list(metrics.keys())\n",
        "    values = list(metrics.values())\n",
        "\n",
        "    plt.bar(labels, values, color='skyblue')\n",
        "    plt.xlabel('Metrics')\n",
        "    plt.ylabel('Scores')\n",
        "    plt.title('Lighthouse Metrics')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_file)\n",
        "    plt.close()\n",
        "\n",
        "# Function to generate a structured PDF report\n",
        "def generate_pdf_report(title, sections, output_file):\n",
        "    pdf = FPDF()\n",
        "    pdf.set_auto_page_break(auto=True, margin=15)\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "    pdf.set_font(\"Arial\", style=\"B\", size=16)\n",
        "    pdf.cell(200, 10, txt=title, ln=True, align='C')\n",
        "\n",
        "    for section_title, content in sections.items():\n",
        "        pdf.set_font(\"Arial\", style=\"B\", size=14)\n",
        "        pdf.cell(200, 10, txt=section_title, ln=True, align='L')\n",
        "        pdf.set_font(\"Arial\", size=12)\n",
        "        pdf.multi_cell(0, 10, content)\n",
        "\n",
        "    pdf.output(output_file)\n",
        "\n",
        "# Main flow of the POC\n",
        "def main():\n",
        "    website_url = input(\"Enter the website URL: \")\n",
        "\n",
        "    # Set file paths\n",
        "    screenshot_file = \"screenshot.png\"\n",
        "    annotated_file = \"annotated_screenshot.png\"\n",
        "    heatmap_file = \"heatmap.png\"\n",
        "    lighthouse_file = \"lighthouse_report.json\"\n",
        "    pdf_report_file = \"website_analysis_report.pdf\"\n",
        "\n",
        "    # Capture and annotate screenshot\n",
        "    asyncio.get_event_loop().run_until_complete(capture_screenshot(website_url, screenshot_file))\n",
        "    annotate_screenshot(screenshot_file, annotated_file)\n",
        "\n",
        "    # Generate a sample heatmap\n",
        "    sample_heatmap_data = np.random.rand(10, 10)\n",
        "    generate_heatmap(sample_heatmap_data, heatmap_file)\n",
        "\n",
        "    # Extract content\n",
        "    text, html = extract_content(website_url)\n",
        "\n",
        "    # Run Lighthouse and visualize metrics\n",
        "    lighthouse_data = run_lighthouse(website_url, lighthouse_file)\n",
        "    metrics = {\"Performance\": 0.9, \"Accessibility\": 0.8, \"Best Practices\": 0.85, \"SEO\": 0.95}\n",
        "    visualize_lighthouse_metrics(metrics, \"lighthouse_metrics.png\")\n",
        "\n",
        "    # Generate PDF report\n",
        "    sections = {\n",
        "        \"Website Text Content\": text[:1000],  # Limiting to 1000 characters for brevity\n",
        "        \"HTML Content\": html[:1000],\n",
        "        \"Lighthouse Metrics\": str(metrics),\n",
        "        \"Heatmap\": \"Heatmap visualization saved to file.\",\n",
        "    }\n",
        "    generate_pdf_report(\"Website Analysis Report\", sections, pdf_report_file)\n",
        "\n",
        "    print(f\"Report generated: {pdf_report_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BADbxLxzHMt4",
        "outputId": "1677782b-ef83-415f-a035-49d0751e594d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-browser is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 54 not upgraded.\n",
            "Requirement already satisfied: pyppeteer in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from pyppeteer) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.11/dist-packages (from pyppeteer) (2024.12.14)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from pyppeteer) (8.5.0)\n",
            "Requirement already satisfied: pyee<12.0.0,>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer) (11.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from pyppeteer) (4.67.1)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.11/dist-packages (from pyppeteer) (1.26.20)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from pyppeteer) (10.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->pyppeteer) (3.21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer) (4.12.2)\n",
            "Enter the website URL: https://shivamportfoliohere.netlify.app/\n",
            "Lighthouse command failed with error: Thu, 16 Jan 2025 17:33:48 GMT LH:ChromeLauncher Waiting for browser.\n",
            "Thu, 16 Jan 2025 17:33:48 GMT LH:ChromeLauncher Waiting for browser...\n",
            "Thu, 16 Jan 2025 17:33:49 GMT LH:ChromeLauncher Waiting for browser.....\n",
            "Thu, 16 Jan 2025 17:33:49 GMT LH:ChromeLauncher Waiting for browser.......\n",
            "Thu, 16 Jan 2025 17:33:50 GMT LH:ChromeLauncher Waiting for browser.........\n",
            "Thu, 16 Jan 2025 17:33:50 GMT LH:ChromeLauncher Waiting for browser...........\n",
            "Thu, 16 Jan 2025 17:33:51 GMT LH:ChromeLauncher Waiting for browser.............\n",
            "Thu, 16 Jan 2025 17:33:51 GMT LH:ChromeLauncher Waiting for browser...............\n",
            "Thu, 16 Jan 2025 17:33:52 GMT LH:ChromeLauncher Waiting for browser.................\n",
            "Thu, 16 Jan 2025 17:33:52 GMT LH:ChromeLauncher Waiting for browser...................\n",
            "Thu, 16 Jan 2025 17:33:53 GMT LH:ChromeLauncher Waiting for browser.....................\n",
            "Thu, 16 Jan 2025 17:33:53 GMT LH:ChromeLauncher Waiting for browser.......................\n",
            "Thu, 16 Jan 2025 17:33:54 GMT LH:ChromeLauncher Waiting for browser.........................\n",
            "Thu, 16 Jan 2025 17:33:54 GMT LH:ChromeLauncher Waiting for browser...........................\n",
            "Thu, 16 Jan 2025 17:33:55 GMT LH:ChromeLauncher Waiting for browser.............................\n",
            "Thu, 16 Jan 2025 17:33:55 GMT LH:ChromeLauncher Waiting for browser...............................\n",
            "Thu, 16 Jan 2025 17:33:56 GMT LH:ChromeLauncher Waiting for browser.................................\n",
            "Thu, 16 Jan 2025 17:33:56 GMT LH:ChromeLauncher Waiting for browser...................................\n",
            "Thu, 16 Jan 2025 17:33:57 GMT LH:ChromeLauncher Waiting for browser.....................................\n",
            "Thu, 16 Jan 2025 17:33:57 GMT LH:ChromeLauncher Waiting for browser.......................................\n",
            "Thu, 16 Jan 2025 17:33:58 GMT LH:ChromeLauncher Waiting for browser.........................................\n",
            "Thu, 16 Jan 2025 17:33:58 GMT LH:ChromeLauncher Waiting for browser...........................................\n",
            "Thu, 16 Jan 2025 17:33:59 GMT LH:ChromeLauncher Waiting for browser.............................................\n",
            "Thu, 16 Jan 2025 17:33:59 GMT LH:ChromeLauncher Waiting for browser...............................................\n",
            "Thu, 16 Jan 2025 17:34:00 GMT LH:ChromeLauncher Waiting for browser.................................................\n",
            "Thu, 16 Jan 2025 17:34:00 GMT LH:ChromeLauncher Waiting for browser...................................................\n",
            "Thu, 16 Jan 2025 17:34:01 GMT LH:ChromeLauncher Waiting for browser.....................................................\n",
            "Thu, 16 Jan 2025 17:34:01 GMT LH:ChromeLauncher Waiting for browser.......................................................\n",
            "Thu, 16 Jan 2025 17:34:02 GMT LH:ChromeLauncher Waiting for browser.........................................................\n",
            "Thu, 16 Jan 2025 17:34:02 GMT LH:ChromeLauncher Waiting for browser...........................................................\n",
            "Thu, 16 Jan 2025 17:34:03 GMT LH:ChromeLauncher Waiting for browser.............................................................\n",
            "Thu, 16 Jan 2025 17:34:03 GMT LH:ChromeLauncher Waiting for browser...............................................................\n",
            "Thu, 16 Jan 2025 17:34:04 GMT LH:ChromeLauncher Waiting for browser.................................................................\n",
            "Thu, 16 Jan 2025 17:34:04 GMT LH:ChromeLauncher Waiting for browser...................................................................\n",
            "Thu, 16 Jan 2025 17:34:05 GMT LH:ChromeLauncher Waiting for browser.....................................................................\n",
            "Thu, 16 Jan 2025 17:34:05 GMT LH:ChromeLauncher Waiting for browser.......................................................................\n",
            "Thu, 16 Jan 2025 17:34:06 GMT LH:ChromeLauncher Waiting for browser.........................................................................\n",
            "Thu, 16 Jan 2025 17:34:06 GMT LH:ChromeLauncher Waiting for browser...........................................................................\n",
            "Thu, 16 Jan 2025 17:34:07 GMT LH:ChromeLauncher Waiting for browser.............................................................................\n",
            "Thu, 16 Jan 2025 17:34:07 GMT LH:ChromeLauncher Waiting for browser...............................................................................\n",
            "Thu, 16 Jan 2025 17:34:08 GMT LH:ChromeLauncher Waiting for browser.................................................................................\n",
            "Thu, 16 Jan 2025 17:34:08 GMT LH:ChromeLauncher Waiting for browser...................................................................................\n",
            "Thu, 16 Jan 2025 17:34:09 GMT LH:ChromeLauncher Waiting for browser.....................................................................................\n",
            "Thu, 16 Jan 2025 17:34:09 GMT LH:ChromeLauncher Waiting for browser.......................................................................................\n",
            "Thu, 16 Jan 2025 17:34:10 GMT LH:ChromeLauncher Waiting for browser.........................................................................................\n",
            "Thu, 16 Jan 2025 17:34:10 GMT LH:ChromeLauncher Waiting for browser...........................................................................................\n",
            "Thu, 16 Jan 2025 17:34:11 GMT LH:ChromeLauncher Waiting for browser.............................................................................................\n",
            "Thu, 16 Jan 2025 17:34:11 GMT LH:ChromeLauncher Waiting for browser...............................................................................................\n",
            "Thu, 16 Jan 2025 17:34:12 GMT LH:ChromeLauncher Waiting for browser.................................................................................................\n",
            "Thu, 16 Jan 2025 17:34:12 GMT LH:ChromeLauncher Waiting for browser...................................................................................................\n",
            "Thu, 16 Jan 2025 17:34:13 GMT LH:ChromeLauncher Waiting for browser.....................................................................................................\n",
            "Thu, 16 Jan 2025 17:34:13 GMT LH:ChromeLauncher Waiting for browser.......................................................................................................\n",
            "Thu, 16 Jan 2025 17:34:13 GMT LH:ChromeLauncher:error connect ECONNREFUSED 127.0.0.1:36913\n",
            "Thu, 16 Jan 2025 17:34:13 GMT LH:ChromeLauncher:error Logging contents of /tmp/lighthouse.IZJ0JYd/chrome-err.log\n",
            "Thu, 16 Jan 2025 17:34:13 GMT LH:ChromeLauncher:error \n",
            "Command '/usr/bin/chromium-browser' requires the chromium snap to be installed.\n",
            "Please install it with:\n",
            "\n",
            "snap install chromium\n",
            "\n",
            "\n",
            "Unable to connect to Chrome\n",
            "\n",
            "Report generated: website_analysis_report.pdf\n"
          ]
        }
      ]
    }
  ]
}